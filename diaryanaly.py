class DiarySenAnaly:
    def __init__(self, input_text):
        self.input_text = input_text

    def split_sentence(self):
        """Splits the input text into sentences."""
        self.seper_senten = self.input_text.split('.')
        self.seper_senten = [sentence.strip() for sentence in self.seper_senten if sentence.strip()]
        return self.seper_senten
    
    ####################################
    ### ê°ì •ë¶„ë¥˜ ëª¨ë¸ ë„£ê¸°#############
        # ê°ì • ë¶„ì„ì„ ìœ„í•œ Hugging Face íŒŒì´í”„ë¼ì¸ ì„¤ì •
    def create_emotion_analyzer(self):
        """Creates and returns a Hugging Face pipeline for emotion analysis using a Korean model."""
        return pipeline("text-classification", model="beomi/kcbert-base")

    def analyze_diary_entry(self, diary_entry, emotion_analyzer):
        """
        Analyzes the emotion of a diary entry using a given emotion analyzer pipeline.

        Parameters:
        diary_entry (str): The diary text to analyze.
        emotion_analyzer (Pipeline): The Hugging Face pipeline object for emotion analysis.

        Returns:
        dict: A dictionary containing the analyzed emotion and the corresponding emoji.
        """
        # ê°ì • -> ì´ëª¨ì§€ ë§¤í•‘
        emotion_to_emoji = {
            "ê³µí¬": "ğŸ˜±",
            "ë†€ëŒ": "ğŸ˜²",
            "ë¶„ë…¸": "ğŸ˜¡",
            "ìŠ¬í””": "ğŸ˜¢",
            "ì¤‘ë¦½": "ğŸ˜",
            "í–‰ë³µ": "ğŸ˜Š",
            "í˜ì˜¤": "ğŸ¤¢"
        }

        # ê°ì • ë¶„ì„ ìˆ˜í–‰
        emotion_result = emotion_analyzer(diary_entry)[0]
        emotion = emotion_result["label"]
        emoji = emotion_to_emoji.get(emotion, "ğŸ¤”")  # ë§¤í•‘ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì´ëª¨ì§€ ì‚¬ìš©
        return {"emotion": emotion, "emoji": emoji}
    ################################
    def sementic_classfiy_f(self, sentences):
        """Dummy function for semantic classification."""
        return [1, 3, 4]  # Replace with your real classification logic
    ########################################


    ### ê°ì • ë¶„ë¥˜ì‹œ ì¤‘ë¦½ ì œì™¸ ì¸ë±ìŠ¤ë¡œ ìˆ˜ì • ##
    def filter_sementic(self, result):
        """Filters sentences based on important emotion labels and combines them with previous sentences."""
        important_labels = {4}  # Labels of interest
        filter_seper_senten = [self.seper_senten[i] for i, label in enumerate(result) if label in important_labels]
        filter_seper_label = [result[i] for i, label in enumerate(result) if label in important_labels]

        # Combine each selected sentence with the previous one
        filter_seper_senten2 = []
        for i in range(len(filter_seper_senten)):
            index = self.seper_senten.index(filter_seper_senten[i])
            if index > 0:
                combined_sentence = self.seper_senten[index - 1] + ' ' + filter_seper_senten[i]
                filter_seper_senten2.append(combined_sentence)
            else:
                filter_seper_senten2.append(filter_seper_senten[i])

        return filter_seper_senten2, filter_seper_label
    

    ####################################
    ### í‚¤ì›Œë“œ ì¶”ì¶œ ëª¨ë¸ ë„£ê¸°#############
    ####################################
    def keyword_extract_f(self, sentences):
        """Dummy function for keyword extraction."""
        return ["keyword1", "keyword2"]  # Replace with your real keyword extraction logic
    ####################################


    def __call__(self):
        """Runs the full analysis when the class is called."""
        # Split sentences
        self.split_sentence()

        # Perform semantic classification
        result_s_model = self.sementic_classfiy_f(self.seper_senten)

        # Filter sentences
        filter_seper_senten, filter_seper_label = self.filter_sementic(result_s_model)

        # decoding label 2 sentic 'str'
        ## ìˆ«ì ë¼ë²¨ì„ ê¸€ìë¡œ ë°”ê¿”ì£¼ëŠ” ì½”ë“œ ì‘ì„± 
        # input  = filter_seper_label -> output = ['í–‰ë³µ', 'ìŠ¬í””', 'í˜ì˜¤']  ë“±ë“±

        # Extract keywords
        result_k_model = self.keyword_extract_f(filter_seper_senten)

        # Output results
        print("Separated Sentences:", self.seper_senten)
        print("sentic classific per sentence:", result_s_model)
        print("Filtered Sentences:", filter_seper_senten)
        print("Filtered sentiment:", filter_seper_label)
        print("Keywords:", result_k_model)
        return filter_seper_senten, filter_seper_label, result_k_model
